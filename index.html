<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="TranSlaDoorss: American Sign Language Classification via One-Shot Learning">
  <meta name="description" content="Web-based ASL fingerspelling (A–Z) prediction using a CLIP model, served via a Django REST API with a Bootstrap webcam frontend and feedback capture.">
  <meta name="keywords" content="ASL, fingerspelling, CLIP, Django, REST API, Bootstrap, webcam, PyTorch, Hugging Face, feedback">
  <meta name="author" content="Benjamin Vogt, Juno Tripathi, Kelly Shieh, Evelyn Hou">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="TranSlaDoorss">
  <meta property="og:title" content="TranSlaDoorss: American Sign Language Classification via One-Shot Learning">
  <meta property="og:description" content="Web-based ASL fingerspelling (A–Z) prediction powered by CLIP, Django REST, and a webcam demo with feedback capture.">
  <meta property="og:url" content="http://localhost:8000/">
  <meta property="og:image" content="http://localhost:8000/static/images/carousel1.jpg">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="TranSlaDoorss - ASL fingerspelling translator preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="Benjamin Vogt, Juno Tripathi, Kelly Shieh, Evelyn Hou">
  <meta property="article:section" content="Software">
  <meta property="article:tag" content="ASL">
  <meta property="article:tag" content="CLIP">
  <meta property="article:tag" content="Django REST">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="TranSlaDoorss">
  <meta name="twitter:creator" content="TranSlaDoorss">
  <meta name="twitter:title" content="TranSlaDoorss: American Sign Language Classification via One-Shot Learning">
  <meta name="twitter:description" content="Web-based ASL fingerspelling (A–Z) prediction powered by CLIP, Django REST, and a webcam demo with feedback capture.">
  <meta name="twitter:image" content="http://localhost:8000/static/images/carousel1.jpg">
  <meta name="twitter:image:alt" content="TranSlaDoorss - ASL fingerspelling translator preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="TranSlaDoorss: American Sign Language Classification via One-Shot Learning">
  <meta name="citation_author" content="Benjamin Vogt">
  <meta name="citation_author" content="Juno Tripathi">
  <meta name="citation_author" content="Kelly Shieh">
  <meta name="citation_author" content="Evelyn Hou">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="Project Snapshot">
  <meta name="citation_pdf_url" content="http://localhost:8000/static/pdfs/sample.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>TranSlaDoorss: American Sign Language Classification via One-Shot Learning</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for the application -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "SoftwareApplication",
    "name": "TranSlaDoorss",
    "applicationCategory": "WebApplication",
    "operatingSystem": "Web",
    "description": "Web-based ASL fingerspelling (A–Z) prediction powered by a CLIP model, exposed through a Django REST API with a Bootstrap/vanilla JS webcam frontend and feedback capture.",
    "author": [
      {
        "@type": "Person",
        "name": "Benjamin Vogt"
      },
      {
        "@type": "Person",
        "name": "Juno Tripathi"
      },
      {
        "@type": "Person",
        "name": "Kelly Shieh"
      },
      {
        "@type": "Person",
        "name": "Evelyn Hou"
      }
    ],
    "url": "http://localhost:8000/",
    "image": "http://localhost:8000/static/images/carousel1.jpg",
    "softwareVersion": "dev",
    "featureList": [
      "ASL fingerspelling (A–Z) translation via CLIPModel/CLIPProcessor",
      "Django REST API endpoints: POST /img_in/translate/ and POST /img_in/feedback/",
      "Bootstrap + vanilla JS webcam frontend with feedback capture",
      "Top-k predictions and confidence reporting"
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "TranSlaDoorss",
    "url": "http://localhost:8000/",
    "logo": "http://localhost:8000/static/images/favicon.ico",
    "sameAs": [
      "http://localhost:8000/"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">TranSlaDoorss: American Sign Language Classification via One-Shot Learning</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">Benjamin Vogt<sup>1</sup>,</span>
              <span class="author-block"><a href="https://github.com/juniper-halo" target="_blank">Juno Tripathi<sup>1</sup></a>,</span>
              <span class="author-block">Kelly Shieh<sup>1</sup>,</span>
              <span class="author-block">Evelyn Hou<sup>1</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup> University of Illinois Urbana-Champaign</span><br>
              <span class="author-block"> December, 2025</span>
            </div>

            <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="#webapp-demo"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-video"></i>
                </span>
                <span>Demo</span>
                </a>
              </span>

            <span class="link-block">
              <a href="#presentation"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fas fa-file-powerpoint"></i>
              </span>
              <span>Presentation</span>
            </a>
          </span>

          <span class="link-block">
            <a href="https://github.com/juniper-halo/TranSlaDoorss.git" target="_blank"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <i class="fab fa-github"></i>
            </span>
            <span>GitHub</span>
          </a>
        </span>
      </div>
    </div>
  </div>
</div>
</div>
</div>
</section>


<!-- Abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified"></div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Demo video -->
<section class="hero teaser" id="webapp-demo">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="static/images/demo-poster.png" autoplay controls muted loop height="100%" preload="metadata">
        <source src="static/videos/demo.mp4" type="video/mp4">
      </video>
    </div>
  </div>
</section>
<!-- End demo video -->

<!-- Overview -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview &amp; API</h2>
        <div class="content has-text-justified">
          <p>
            TranSlaDoorss is a web-based ASL fingerspelling (A–Z) translator that pairs a CLIPModel/CLIPProcessor backend with a Django REST API and a Bootstrap/vanilla JS webcam frontend. Predictions are surfaced with confidences and optional top-k, and a feedback endpoint stores labeled frames for future retraining.
          </p>
          <p>
            Stack highlights: Django 5.2 + DRF, PyTorch + Hugging Face Transformers, PIL preprocessing, conda environment, and Jest/pytest coverage for frontend/backend behaviors.
          </p>
          <h3 id="translate-endpoint">/img_in/translate/</h3>
          <ul>
            <li>POST multipart/form-data with <code>image</code> (required) and optional <code>top_k</code> (1–26, default 1).</li>
            <li>Validates presence and integrity with PIL; missing or corrupt images return 400 with clear error strings.</li>
            <li>Success payload always includes <code>translation</code> and <code>prediction</code>; <code>top_predictions</code> appears when <code>top_k</code> &gt; 1 to match frontend/UI expectations.</li>
          </ul>
          <h3 id="feedback-endpoint">/img_in/feedback/</h3>
          <ul>
            <li>POST multipart/form-data with <code>image</code>, <code>predicted_label</code>, and <code>correct_label</code> (single letters A–Z; serializer uppercases).</li>
            <li>Stores uploads under <code>backend/feedback_images</code> with labels and timestamp; responds 201 with id and echoed labels.</li>
          </ul>
          <h3 id="model-behavior">Model &amp; inference</h3>
          <ul>
            <li>CLIP-based predictor precomputes prompts for letters A–Z and selects device (CUDA → MPS → CPU) with graceful CPU fallback.</li>
            <li>Model id resolution: explicit arg → env <code>ASL_MODEL_ID</code> → <code>ml/saved_weights/best_checkpoint.json</code> → default <code>openai/clip-vit-base-patch32</code>.</li>
            <li>Top-k predictions produced via softmax over prompt similarities; predictor cached to avoid reloads per request.</li>
          </ul>
          <h3 id="setup">Local setup</h3>
          <ul>
            <li><code>conda env create -f env/environment_unified.yaml</code> then <code>conda activate transladoorss</code>.</li>
            <li><code>cd backend</code> → <code>python manage.py migrate</code> → <code>python manage.py runserver</code> (DEBUG serves <code>frontend/index.html</code> and static assets).</li>
            <li>Env vars: <code>SECRET_KEY</code> required; optional <code>DEBUG</code>, <code>ALLOWED_HOSTS</code>, <code>ASL_MODEL_ID</code>, <code>ASL_MODEL_DEVICE</code>.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper overview -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/carousel1.jpg" alt="Webcam capture feeding the translation endpoint" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Webcam capture via <code>getUserMedia</code> streams a frame to <code>/img_in/translate/</code> using the Bootstrap/vanilla JS frontend.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel2.jpg" alt="Translation response and UI update" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Translate response returns <code>prediction.letter</code> and <code>prediction.confidence</code> (or <code>top_predictions</code>) to populate the UI.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel3.jpg" alt="Feedback submission flow" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
         Feedback endpoint stores the captured frame with <code>predicted_label</code> and <code>correct_label</code> under <code>backend/feedback_images</code>.
       </h2>
     </div>
     <div class="item">
      <img src="static/images/carousel4.jpg" alt="Model checkpoint handling and device selection" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        CLIP-based predictor resolves checkpoints automatically and falls back from CUDA→MPS→CPU when kernels are unavailable.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Frontend walkthrough</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Model, data, and UX clips</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->





<!-- Repo + setup notes -->
<section class="hero is-small is-light" id="repo-details">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Repo &amp; setup notes</h2>
      <div class="content">
        <p>Repository: <code>transladoorss-model-dev-env</code> (<a href="https://github.com/juniper-halo/TranSlaDoorss.git" target="_blank">GitHub</a>). In DEBUG, Django serves <code>frontend/index.html</code> plus static <code>/js</code>, <code>/css</code>, <code>/assets</code>, and <code>/media</code> (uploads under <code>backend/feedback_images</code>).</p>
        <ul>
          <li>Frontend: static Bootstrap + vanilla JS (webcam capture, fetch to API); Jest tests in <code>frontend/tests/scripts.test.js</code>.</li>
          <li>Backend: Django + DRF; pytest/pytest-django cover API behaviors. MEDIA_ROOT switches to a temp dir during tests.</li>
          <li>Known gaps: <code>backend/tests/test_img_translate.py</code> has merge-conflict markers; <code>ml/development/clip_fine_tuned.py</code> needs loop fixes; feedback storage exists but retraining is not wired up.</li>
          <li>Assets: replace <code>static/images/favicon.ico</code> and consider adding a <code>static/images/social_preview.png</code> for richer sharing cards.</li>
        </ul>
        <p>You can swap <code>static/pdfs/sample.pdf</code> for an architecture or API reference if you want a downloadable artifact.</p>
      </div>
    </div>
  </div>
</section>
<!--End repo + setup notes -->



<!-- Sample requests -->
  <section class="section" id="api-examples">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">Sample requests</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy curl examples to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code># Translate a captured frame (top-3 letters)
curl -X POST http://localhost:8000/img_in/translate/ \
  -F "image=@frame.png" \
  -F "top_k=3"

# Send feedback for a prediction
curl -X POST http://localhost:8000/img_in/feedback/ \
  -F "image=@frame.png" \
  -F "predicted_label=A" \
  -F "correct_label=A"</code></pre>
    </div>
</section>
<!--End sample requests -->

<!-- Presentation embed -->
<section class="hero is-small is-light" id="presentation">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Presentation</h2>
      <iframe
        class="presentation-frame"
        src="static/pdfs/transladoors_presentation_v.10.pdf"
        frameborder="0">
      </iframe>
    </div>
  </div>
</section>
<!-- End presentation embed -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
